## 实验报告

### 学号姓名：201250104 苏致成

### Title：End-to-end Structure-Aware Convolutional Networks for Knowledge Base Completion

### 主题：用于知识库构建的端到端结构感知卷积网络



[toc]



### 一、摘要与介绍翻译

#### 1.1 摘要翻译

​		知识图谱的嵌入一直是知识库构建的一个活跃的研究课题，从最初的 $TransE$、$TransH$、$DistMult$ 等逐步发展到目前最先进的 $ConvE$ 。$ConvE$ 在嵌入和多层非线性特征上使用二维卷积来建模知识图。该模型可以有效地训练，并可扩展到大型知识图。

​		然而，$ConvE$ 的嵌入空间中没有结构强制。最近的图卷积网络通过成功地利用图的连通结构提供了另一种学习图节点嵌入的方法。在这项工作中，我们提出了一种新型的端到端结构化软件卷积网络（$SACN$），它能够同时吸纳 $GCN$ 和 $ConvE$ 的优点。$SACN$ 由加权图卷积网络（$WGCN$）的编码器和卷积网络 $ConvTransE$ 的解码器组成。$WGCN$ 利用了知识图节点结构、节点属性和边缘关系类型。它具有可学习的权重，可以适应本地聚合中使用的邻居信息量，从而实现更精确的图形节点嵌入。

​		在 $WGCN$ 中，图中的节点属性表示为其他节点。解码器 $Conv-TransE$ 使最先进的 $ConvE$ 能够在实体和关系之间进行转换，同时保持与 $ConvE$ 相同的链路预测性能。我们在标准 $FB15k-237$ 和 $WN18RR$ 数据集上证明了提出的 $SACN$ 的有效性，并且从 $HITS@1, HITS@3$ 和$HITS@10$ 指标来看，它比最先进的 $ConvE$ 提高了约 $10\%$ 。

 

#### 1.2 介绍翻译

​		近年来，大型知识库如 $Freebase$ （$Bollacker$ 等人，2008年）、$DBpedia$（$Auer$等人，2007年）、$NELL$（$Carlson$ 等人，2010年）和$YAGO3$（$Mahdisoltani$、$Biega$ 和 $Suchanek$ ，2013年）被建立以存储关于共同事实的结构化信息。知识库是多关系图，其节点表示实体，边表示实体之间的关系，边用不同的关系标记。这些关系以$（s，r，o）$三元组的形式组织（例如，实体 $s$=$Abraham Lincoln$，关系$r$=$DateOfBirth$，实体$o$= $02-12-1809$ ）。这些知识库广泛用于网络搜索、推荐和问答系统中。

​		尽管这些知识库已经包含了数百万个实体和三元组，但与现有事实和新增加的现实世界知识相比，它们还远远不够完整。因此，为了在现有三元组的基础上预测新的三元组，从而进一步扩展知识库，完成知识库非常重要。

​		知识库构建的最新活跃研究领域之一是知识图嵌入：它对连续低维向量空间中的实体和关系的语义进行编码（称为嵌入）。然后，这些嵌入用于预测新的关系。从一种简单有效的方法 $TransE$（$Bordes\space et\space al.2013$）开始，人们提出了许多知识图嵌入方法，如 $TransH$（ $Wang \space et\space  al.2014$）、$TransR$（$Lin\space et\space al.2015$）、$DistMult$（$Y \space ang\space et\space  al.2014$）、$TransD$（$Ji \space et\space  al.2015$）、$CompleEx$（$Trouillon\space et\space  al.2016$）、$STransE$（$Nguyen\space et\space al.2016$）。一些调查（$Nguyen\space 2017；Wang\space et\space al.2017$）给出了这些嵌入方法的详细信息和比较。

​		最新的 $ConvE$（$Dettmers et al.2017$）模型在嵌入和多层非线性特征上使用二维卷积，并在用于知识图链接预测的通用基准数据集上实现了最先进的性能。在 $ConvE$中， $s$ 和 $r$ 的嵌入被重新变形并连接到一个输入矩阵中，然后传送到卷积层。$n×n$的卷积滤波器用于输出跨不同维嵌入项的特征映射。因此，$ConvE$ 不保留 $TransE$ 的平移属性，$TransE$是一种附加的嵌入向量操作：$es+er≈ eo$（$Nguyen$ 等人，$2017$）。在本文中，我们删除了 $ConvE$ 的变形步骤，并直接在s和r的相同维度上应用卷积滤波器。与原始的 $ConvE$ 相比，这个改动具有更好的性能，并且具有直观的解释，保持了嵌入三元组$（es，er，eo）$中s，r和o的全局学习度量相同。我们将此嵌入命名为 $ConvTransE$。

​		$ConvE$也没有将知识图中的连通结构合并到嵌入空间中。相比之下，图卷积网络已成为创建节点嵌入的有效工具，该节点嵌入可聚合每个节点的图邻域中的本地信息（ $Kipf\space and\space  Welling\space 2016b$;  $Hamilton,\space Ying$ 和 $Leskovec\space 2017a$;  $Kipf$ 和 $Welling\space 2016a$;  $Pham\space et\space al. 2017$;  $Shang\space et\space  al$. 2018）。$GCN$ 模型还有其他优点（$Hamilton、Ying$和 $Leskovec\space 2017b$），例如利用与节点相关的属性。它们还可以在计算每个节点的卷积时采用相同的聚合方案，这可以被视为一种正则化方法，并提高效率。尽管可扩展性最初是GCN模型的一个问题，但最新的高效数据 $GCN$ ，也就是$PinSage$（$Ying$ 等人，2018），能够处理数十亿级别的节点和边。

​		本文提出了一种端到端的图结构感知卷积网络（$SACN$），它将 $GCN$ 和 $ConvE$ 的所有优点结合在一起。$SACN$ 由加权图卷积网络（$WGCN$）的编码器和卷积网络 $Conv-TransE$ 的解码器组成。

​		$WGCN$ 利用知识图节点结构、节点属性和关系类型。它具有可学习的权重来确定本地聚合中使用的邻居信息量，从而实现更精确的图节点嵌入。节点属性作为附加属性添加到 $WGCN$ 中以便于集成。$WGCN$ 的输出成为解码器 $ConvTransE$ 的输入。$ConvTransE$ 与 $ConvE$ 相似，但不同的是，$ConvTransE$ 保持了实体和关系之间的转化特性。

​		我们证明出 $ConvTransE$ 比 $ConvE$ 表现更好，并且在标准基准数据集中，我们的 $SACN$ 在 $ConvTransE$ 的基础上进一步提高。我们的模型和实验的代码是公开的。我们的贡献总结如下：

+ 我们提出了一个端到端网络学习框架 $SACN$，它同时利用了 $GCN$ 和$ ConvTransE$ 。编码器GCN模型利用图形结构和图形节点的属性。解码器 $ConvTransE$ 通过特殊卷积简化了 $ConvE$ ，并保持了 $TransE$ 的转化特性和 $ConvE$ 的预测性能；    

+ 我们在标准 $FB15k-237$ 和 $WN18RR$ 数据集上证明了我们提出的 $SACN$ 的有效性，并在 $HITS@1, HITS@3和HITS@10$ 数据集上显示出和最先进的 $ConvE$ 相比大约有 $10\%$的改进。

 

### 二、问题描述

####  2.1 传统模型问题

传统模型主要存在以下问题：

+ 只对关系型三元组进行建模，而忽略了节点的属性。
+ 没有将节点的结构化信息纳入考虑范围。

因此，随着图神经网络的提出与发展，使得 $GCN$ 成为了获取图结构化信息的利器。因此，这里运用 $WGCN$ 模型，使得节点的结构化信息得以充分利用。并根据最新的用卷积解决知识图谱嵌入问题的研究，改进了 $ConvE$ 模型，使其保留了平移特性，构建了 $Conv-TransE$模型，将上述两个模型一个作为编码器，一个作为解码器，构建了整个 $SACN$ 模型，用于完善知识图谱。



### 三、输入、输出、模型算法描述

#### 3.1 输入

##### 3.1.1 整体输入

​		这里选取了三个知识图谱的基准数据集来评估链路预测的性能，分别为 $FB15k-237$、$WN18RR$、$FB15k-237-Attr$。

+ $FB15k-237$ ： $FB15k$ 的子集，删除了逆向关系等。

+ $WN18RR$ ：由 $WN18$ 创建而来，且 $WN18$ 是 $WordNet$ 的一个子集。

+ $FB15k-237-Attr$ ：由 $FB15k-237$ 创建而来。

  

​		以下描述了数据集中的各指标数量：

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221008205107425.png" alt="image-20221008205107425" style="zoom:80%;" />

##### 3.1.2 输入解析

​		以 $FB15k-237$ 为例，分析其数据结构。

+ **entity2id.txt​**
  + 实体和id对
  + 数据格式部分截图如下：
  + <img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018093013695.png" alt="image-20221018093013695" style="zoom:50%;" />
+ **relation2id.txt**
  + 关系和id对
  + 数据格式部分截图如下：
  + <img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018093102738.png" alt="image-20221018093102738" style="zoom:50%;" />
+ **train.txt**
  + 训练集三元组（实体，实体，关系）
+ **test.txt**
  + 测试集三元组（实体，实体，关系）

​	



##### 3.1.3 Conv-TransE的输入



<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914161550749-523775212.png" alt="img" style="zoom:80%;" />

模型的整体框架为 $WGCN$ 模块提取实体 $embedding$ 表示，再将实体 $embedding$ 表示作为 $ConvTransE$ 模块的输入。



#### 3.2 输出

输出为模型在不同数据集上正确率。详细结果参见后文。

##### 3.2.1 ConvTransE

此数据是在 $FB15k-237$ 数据集上运行 $ConvTransE$  ，并将 $epoch$ 设置为300。原因如下：

1. 根据论文后续关于收敛性的分析，可以看出当 $epoch$ 数量达到300时，$Hits@n$ 和 $MRR$ 都达到收敛。
2. 因为本模型运算量巨大，基于节省经费方面考虑。

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018114614189.png" alt="image-20221018114614189" style="zoom:67%;" />

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018114649186.png" alt="image-20221018114649186" style="zoom:67%;" />



##### 3.2.2 SACN

此数据是在 $FB15k-237$ 数据集上运行 $SACN$  ，并将 $epoch$ 设置为300。原因如下：

1. 根据论文后续关于收敛性的分析，可以看出当 $epoch$ 数量达到300时，$Hits@n$ 和 $MRR$ 都达到收敛。

2. 因为本模型运算量巨大，基于节省经费方面考虑。且方便与上述模型对比。

   

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018114426321.png" alt="image-20221018114426321" style="zoom:67%;" />

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018114507908.png" alt="image-20221018114507908" style="zoom:67%;" />

结果如下：

| 模型       | Hits@10 | Hits@3 | Hits@1 | MRR   |
| ---------- | ------- | ------ | ------ | ----- |
| ConvTransE | 0.514   | 0.368  | 0.245  | 0.334 |
| SACN       | 0.524   | 0.387  | 0.253  | 0.337 |

论文中原数据如下：

| 模型       | Hits@10 | Hits@3 | Hits@1 | MRR  |
| ---------- | ------- | ------ | ------ | ---- |
| ConvTransE | 0.51    | 0.37   | 0.24   | 0.33 |
| SACN       | 0.54    | 0.39   | 0.26   | 0.35 |

+ 数据基本一致，可以看到在 $epoch$ 数量为300时，两模型均接近收敛。因为 $SACN$ 后续仍有小幅增长（查看关于收敛性分析的章节），因此和论文中数值有小幅出入。
+ 因为时间成本及经济成本等原因，对其他模型和其他数据集暂时不予复现。





#### 3.3 模型算法描述

##### 3.2.1 GCN回顾

​		$GCN$ 的定义的核心思想为：每个节点依次作为聚合的中心节点，对于每个中心节点，聚合邻居节点的本层特征来作为中心节点下一层特征的表示。在 $GCN$ 中前向迭代公式为：
$$
h_{i}^{l+1}=\sigma(\sum_{j\in N_{i}}g(h_{i}^{l},h_{j}^{l}))
$$
​		其中，$N_{i}$表示 $i$ 及 $i$ 的邻居节点的集合。$h^{l}$ 为该中心节点在第 $l$ 层的向量表示。$g(par1,par2)$ 表示信息传递函数，定义为：
$$
g(h_{i}^{l},h_{j}^{l})=h_{j}^{l}W^{l}\\
h_{j}^{l}\in R^{F^{l}},W^{l}\in R^{F^{l}\times F^{l+1}}
$$
​		上述操作将线性变换后邻居节点的向量传递到中心节点，实现 $GCN$ 层中的聚合操作。 $GCN$ 层堆叠次数越多，中心节点聚合的邻居节点的范围越广。



##### 3.2.2 WGCN改进

​		$WGCN$ 与 $GCN$ 的主要区别在于，在上述聚合过程中对不同的关系以不同的权重，定义权重为 $\alpha_{t}$ ，$1\le t \le T$ ,其中 $T$ 为关系总数，$\alpha_{t}$ 为可学参数。因此在 $WGCN$ 中前向迭代公式为：
$$
h_{i}^{l+1}=\sigma(\sum_{j\in N_{i}}\alpha_{t}^{l}g(h_{i}^{l},h_{j}^{l}))
$$
​		其中信息传递参数与上述一致。并且此处可以将中心节点和邻居节点进行分离，将上述公式写作：
$$
h_{i}^{l+1}=\sigma(\sum_{j\in N_{i}}\alpha_{t}^{l}h_{j}^{l}W^{l}+h_{i}^{l}W^{l})
$$
​		将其转换为矩阵形式：
$$
A^{l}=\sum _{t=1}^{T}(\alpha_{t}^{l}A_{t})+I
$$
​		上述表达式中，$A_{t}$ 表示第 $t$ 个关系构成的 $0-1$ 邻接矩阵，0表示没有直连边，1表示有直连边。因此，可以转为类似原始的 $GCN$ 递推公式:
$$
H^{l+1}=\sigma (A^{l}H^{l}W^{l})
$$
​		根据上述的转换可以将多关系图转为多个具有不同强弱关系的单关系图。如下图所示：

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914174040090-778298841.png" alt="img" style="zoom:60%;" />



##### 3.2.3 属性节点

​		因为每个节点的属性数量少，而且各不相同，因此，属性向量十分稀疏。在本工作中，将节点的属性同样作为图的节点，这样相同属性的节点可以共享信息。



##### 3.2.4 Conv-TransE

​		$Conv-TransE$ 类似于 $ConvE$ ，通过对 $(s,r)$ 和 $o$ 进行相似度打分以预测关系是否成立。不同之处在于此处省略了 $ConvE$ 的 $reshape$ 操作。

以下是知识图谱经典的打分函数。

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914175613469-2107401389.png" alt="img" style="zoom:60%;" />



​		$Conv-TransE$ 中总体流程如图所示：

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914175646557-1168165690.png" alt="img" style="zoom:70%;" />

步骤如下：

1. 将 $WGCN$ 得到的实体 $s$ 的嵌入式向量表示和预训练的关系 $r$ 的嵌入式向量表示进行连接操作，转化成一个 $2*n$ 维的矩阵。
2. 对上述矩阵进行卷积操作，通过多个相同尺寸的卷积核，得到图中所示的特征图。
3. 将特征图拼接形成一个向量，通过全连接层进行降维。
4. 将上述得到的向量与 $WGCN$ 生成的所有向量分别进行点积操作，计算 $(s,r)$ 和所有待选的 $o$ 的相似度。
5. 相似度通过 $Sigmoid$ 函数后，取相似度最高的作为预测的实体 $o$ 。

公式补充说明：

+ 整个网络的损失可以定义为 $(s,r)$ 和待选的 $o$ 构成的三元组是否成立的二分类交叉熵。公式为：
  $$
  \mathcal{L}(p,t)=-\frac{1}{N}\sum_{i}(t_{i}\cdot log(p_{i})+(1-t_{i})\cdot log(1-p_{i}))
  $$

+ $decoder$ 中的卷积公式如下：
  $$
  m_{c}(e_{s},e_{r},n)=\sum_{r=0}^{K-1}\omega_{c}(\tau,0)\hat{e_{s}}(n+\tau)+\omega(\tau,1)\hat{e_{r}}(n+\tau)
  $$
  其中，$\omega_{c}$ 是第 $c$ 个内核的参数，K是内核大小。

+ 打分函数的公式为:
  $$
  \psi (e_{s},e_{o})=f(vec(M(e_{s},e_{r}))W)e_{o}
  $$
  其中，$M(var1,var2)$ 表示卷积操作，$vec(var1)$ 表示拉直操作，$f(var1)$ 表示激活函数。

+ 将打分函数通过 $Sigmoid$ 函数后，得到 $(s,r)$ 和待选的 $o$ 构成的三元组成立的概率。公式为：
  $$
  p(e_{s},e_{r},e_{o})=\sigma (\psi (e_{s},e_{o}))
  $$




### 四、评价指标及其计算公式



#### 4.1 计算公式

​		本公式为对 **评估方案** 中的 $rank_{i}$ 函数进行说明。

​		本过程在算法描述中已有涉及。首先通过打分函数和 $Sigmoid$ 函数进行计算$(s,r)$ 和 $o$ 的概率：
$$
p(e_{s},e_{r},e_{o})=\sigma (\psi (e_{s},e_{o}))
$$
​		对上述概率进行排序，概率最高的即为预测的结果。根据测试集中的正确结果即可计算出其正确率。根据上述打分函数，也可以知道排序的结果（$rank_{i}$）。



#### 4.2 评估方案

##### 4.2.1 Hits@n

​		该指标是指在链接预测中排名小于 $n$ 的三元组的平均占比。具体的计算公式为：
$$
HITS@n=\frac{1}{|S|}\sum_{i=1}^{|S|}\amalg(rank_{i}\le n)
$$
​		其中, $\amalg()$ 表示若预测成功为1，反之为0。$S$ 是三元组集合，$|S|$ 是三元组集合个数。$rank_{i}$ 指第 $i$ 个三元组的链接预测排名。

​		一般而言，$n$ 取1、3、10。本实验中亦选择1、3、10 作为指标。 

##### 4.2.2 MRR

​		实验使用正确实体的比例排名前1、3、10的平均倒数排名 $(MRR)$ 作为度量值。同时，由于知识图中存在一些损坏的三元组，因此在排名之前首先过滤掉所有无效的三元组。具体计算公式如下：
$$
MRR=\frac{1}{|S|}\sum_{i=1}^{|S|}\frac{1}{rank_{i}}=\frac{1}{|S|}(\frac{1}{rank_{1}}+\frac{1}{rank_{2}}+...\frac{1}{rank_{|S|}})
$$
​		其中，上述的参数在 $Hits@n$ 中已进行说明。





### 五、对比方法及引用出处

#### 5.1 对比方法

​		$SACN$ 是在 $Conv-TransE$ 的基础上衍生出来的，因此首先与其进行对比。同时，这里使用更多的知识图谱嵌入工具与 $SACN$ 进行对比。对比方法为利用知识图谱和 $SACN$ 对同一知识图谱进行训练以及链接预测工作，计算其准确率 $(Hits@n)$ 以及 $MRR$。

​		下图为对比结果：

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914192220381-859469588.png" alt="img" style="zoom:80%;" />

​		详细分析见结果部分。



#### 5.2 引用出处

以下是几种与 $SACN$ 对比模型的出处。

DistMult：[Embedding Entities and Relations for Learning and Inference in Knowledge Bases](https://arxiv.org/abs/1412.6575)

ComplEx：[Complex Embeddings for Simple Link Prediction](https://arxiv.org/abs/1606.06357v1)

R-GCN：[Modeling Relational Data with Graph Convolutional Networks](https://arxiv.org/pdf/1703.06103.pdf)

ConvE：[Convolutional 2D Knowledge Graph Embeddings](https://arxiv.org/abs/1707.01476)



### 六、结果

#### 6.1 链接预测

##### 6.1.1 结果展示

​	在链接预测任务的实验中，结果如图所示。



![img](https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914192220381-859469588.png)



##### 6.1.2 结论

1. 若不考虑 $SACN$ 。
   + 在 $FB15k-237$ 数据集中，$Conv-TransE$ 模型的$Hits@10$ 比 $ConvE$ 提高了$4.1\%$ ， $Hits@3$ 提高了 $5.7\%$ 。 
   + 在 $WN18RR$ 数据集中，$Conv-TransE$ 模型的$Hits@10$ 比 $ConvE$提高了$8.3\%$ ， $Hits@3$ 提高了 $9.3\%$ 。 
   + 得出结论：使用神经网络的 $Conv-TransE$ 保持了实体和关系之间的平移特性，展示出更好的性能。
2. 若考虑 $SACN$。
   + 在 $FB15k-237$ 数据集中，$SACN$ 模型的$Hits@10$ 比 $ConvE$提高了$10.2\%$ ， $Hits@3$ 提高了 $11.4\%$， $Hits@1$提高了 $8.3\%$  ，$MRR$ 的值提高了 $9.4\%$。
   + 在 $WN18RR$ 数据集中，$SACN$ 模型的$Hits@10$ 比 $ConvE$提高了$12.5\%$ ， $Hits@3$ 提高了 $11.6\%$， $Hits@1$提高了 $10.3\%$  ，$MRR$ 的值提高了 $2.2\%$。
3. 若考虑 $SACN$ ，并且将节点属性添加到 $SACN$ 模型中。
   + 在 $FB15k-237-Attr$ 数据集中，$SACN$ 模型的$Hits@10$ 比 $ConvE$提高了$12.2\%$ ， $Hits@3$ 提高了 $14.3\%$， $Hits@1$提高了 $12.5\%$  ，$MRR$ 的值提高了 $12.5\%$。
   + 在 $FB15k-237-Attr$ 数据集中，$SACN$ 模型的$Hits@10$ 比没有使用属性的 $SACN$提高了$1.9\%$ ， $Hits@3$ 提高了 $2.6\%$， $Hits@1$提高了 $3.8\%$  ，$MRR$ 的值提高了 $2.9\%$。



#### 6.2 收敛分析

##### 6.2.1 结果展示

若使用 $FB15k-237-Attr$ , $SACN$ 、$Conv-TransE$、$SACN+Attr$ 三者的 $Hits@1$ 和 $MRR$ 收敛性如下：

<img src="C:\Users\Dudu\AppData\Roaming\Typora\typora-user-images\image-20221018110117539.png" alt="image-20221018110117539" style="zoom:67%;" />

##### 6.2.2 结论

1. $Conv-TransE$ 在 120 个 $Epoch$ 后性能达到最优、停止增长，但 $SACN $ 仍保持增长。
2. 当使用 $FB15k-237-Attr$ 数据集，$SACN+Attr$ 的模型效果总是比 $SACN$ 高。 



####  6.3 卷积核大小的选择

##### 6.3.1 结果展示

​		针对参数的调节部分，这里尝试了不同大小的卷积核，此处给出针对不同数据集的卷积核大小的结果。

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914192455579-1154347209.png" alt="img" style="zoom:60%;" />

##### 6.3.2 结论

1. 如果增加核大小，$Hits@1$、$Hits@3$、$Hits@10$、$MRR$ 指标均能增加。
2. 最佳内核大小取决于具体任务。



#### 6.4 度对性能的影响

##### 6.4.1 结果展示

这里比较了 $Conv-TransE$  和 $SACN$ 在不同的度下的性能表现。

<img src="https://img2018.cnblogs.com/blog/1455708/201909/1455708-20190914192600493-2141944294.png" alt="img" style="zoom:60%;" />

##### 6.4.2 结论

+ 在度较低的节点中，$SACN$ 的表现优于 $Conv-TransE$ ，因为邻居节点直接能共享更多的信息。
+ 在度较高的节点中，$SACN$ 的表现不如 $Conv-TransE$ ，因为较多的邻居节点使得较为重要的邻居的信息被过度稀释，因此不如 $Conv-TransE$。

